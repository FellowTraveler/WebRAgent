# ğŸ” WebRAgent

A Retrieval-Augmented Generation (RAG) web application built with Flask and Qdrant.

Â© 2024 Dennis Kruyt. All rights reserved.

## Introduction

**WebRAgent** is a powerful Retrieval-Augmented Generation system that merges Large Language Models (LLMs) with a vector database (Qdrant) to provide contextually rich answers to user queries. By offering various search modesâ€”including **Collection Search** for internal documents, **Web Search** via SearXNG, and a more comprehensive **Deep Web Search**â€”WebRAgent ensures you can find the information you need quickly and thoroughly. For more complex questions, WebRAgentâ€™s **Agent Search** functionality breaks down queries into sub-problems and compiles a holistic answer. You can also visualize the relationships between concepts using the built-in **Mind Map** generator. 

If you prefer to keep your LLM-powered workflows completely private and self-contained, you can integrate Ollama into WebRAgent. Ollama runs entirely on your local machine.

## ğŸ“· Screenshots

### Search
![Search](screenshots/search.png)

### Context
![Context](screenshots/context.png)

### Collections
![Collections](screenshots/collections.png)

### Upload
![Upload](screenshots/upload.png)

## ğŸ“‹ Overview

This application implements a RAG system that combines the power of Large Language Models (LLMs) with a vector database (Qdrant) to provide context-enhanced responses to user queries. It features:

- ğŸ’¬ User query interface for asking questions  
- ğŸ” Admin interface for managing document collections  
- ğŸ“„ Document processing and embedding  
- ğŸ¤– Integration with multiple LLM providers (OpenAI, Claude, Ollama)

## âœ¨ Features

### Collection Search
Search within your **document collections** for relevant information. Simply select a specific collection from the dropdown menu to limit queries to that collectionâ€™s contents.

### Web Search
Search the internet for information using **SearXNG**. This option fetches search results from various search engines and synthesizes them with LLMs for a comprehensive answer.

### Deep Web Search
An **enhanced web search** that scrapes and processes the full content of web pages to extract more detailed information. This option:
- Retrieves search results from the web  
- Scrapes the full content of each page  
- Analyzes the content to extract relevant information  
- Takes longer to process but provides more **comprehensive** results  

### Agent Search
Enhances the search process by breaking down complex questions into smaller, more focused sub-queries:
- Analyzes your question to identify key components  
- Creates targeted sub-queries for each component  
- Processes each sub-query separately  
- Synthesizes a comprehensive answer from all results  
- Particularly useful for **multi-part questions**  

#### Agent Strategies
- **Direct Decomposition**: Immediately breaks your query down into sub-queries before searching  
- **Informed Decomposition**: First performs a preliminary search, then creates targeted follow-up queries based on initial findings  

### Generate Mind Map
Automatically creates a **visual mind map** representing the answer, helping you understand the relationships between concepts at a glance.

### Number of Results
Controls how many source documents or web pages will be used to generate the answer. Increasing this number can provide a more thorough overview but may increase processing time.

### Additional Highlights
- ğŸ–¥ï¸ **User Interface**: A clean, intuitive interface to submit queries and receive LLM responses  
- ğŸ” **Vector Search**: Retrieve relevant document snippets based on semantic similarity  
- ğŸ‘¤ **Admin Interface**: Securely manage collections and upload documents  
- ğŸ“ **Document Processing**: Automatically extract text, chunk, embed, and store documents  
- ğŸ§  **Multiple LLM Support**: Configure your preferred LLM provider (OpenAI, Claude, Ollama)  
- ğŸ” **Dynamic Embedding Models**: Automatically detects and uses available embedding models from all configured providers  

## ğŸ“‹ Prerequisites

- ğŸ Python 3.8+  
- ğŸ—„ï¸ [Qdrant](https://qdrant.tech/documentation/quick-start/) running locally or remotely  
- ğŸ”‘ API keys for your chosen LLM provider  

## ğŸš€ Installation

### ğŸ’» Option 1: Local Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/dkruyt/WebRAgent.git
   cd WebRAgent
   ```

2. **Create and activate a virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Copy the example environment file and configure it**:
   ```bash
   cp .env.example .env
   ```
   Then edit the `.env` file with your preferred settings. For example:
   ```
   # API Keys for LLM Providers (uncomment and add your keys for the providers you want to use)
   # At least one provider should be configured
   #OPENAI_API_KEY=your_openai_api_key_here
   #CLAUDE_API_KEY=your_claude_api_key_here
   
   # Ollama Configuration (uncomment to use Ollama)
   #OLLAMA_HOST=http://localhost:11434
   
   # Qdrant Configuration
   QDRANT_HOST=localhost
   QDRANT_PORT=6333
   
   # SearXNG Configuration
   SEARXNG_URL=http://searxng:8080
   
   # Flask Secret Key (generate a secure random key for production)
   FLASK_SECRET_KEY=change_me_in_production
   
   # Admin User Configuration
   ADMIN_USERNAME=admin
   ADMIN_PASSWORD=change_me_in_production
   ```

   The system will automatically detect and use models from the providers you've configured. For example:
   - If `OPENAI_API_KEY` is set, it will use OpenAI models for both LLM and embeddings.
   - If `CLAUDE_API_KEY` is set, it will use Claude models for LLM.
   - If `OLLAMA_HOST` is set, it will use Ollama models for both LLM and embeddings.
   - Sentence Transformers will be used as a fallback embedding model.

5. **Ensure Qdrant is running** locally or specify a remote instance in the `.env` file.

6. **If using Ollama**, make sure itâ€™s running locally or specify the remote instance in the `.env` file.

7. **Start the application**:
   ```bash
   python run.py
   ```

8. **Access the application** at `http://localhost:5000`.

### ğŸ³ Option 2: Docker Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/dkruyt/WebRAgent.git
   cd WebRAgent
   ```

2. **Start the application with Docker Compose**:
   ```bash
   docker-compose up -d
   ```

3. The following services will be available:
   - ğŸŒ **RAG Web Application**: `http://localhost:5000`
   - ğŸ“Š **Qdrant Dashboard**: `http://localhost:6333/dashboard`
   - ğŸ” **SearXNG Search Engine**: `http://localhost:8080`

4. To shut down the application:
   ```bash
   docker-compose down
   ```

### ğŸ“¥ Pre-downloading Ollama Models

If you want to pre-download Ollama models before starting the application:

```bash
# For main LLM models
ollama pull llama2
ollama pull mistral
ollama pull gemma

# For embedding models
ollama pull nomic-embed-text
ollama pull all-minilm
```

The system will automatically detect these models if they're available in your Ollama installation.

## ğŸ“– Usage

### ğŸ” User Interface
1. **Navigate to the home page** (`http://localhost:5000`).  
2. **Choose your search method**:
   - **Collection Search**: Select a collection from the dropdown menu  
   - **Web Search**: Toggle the â€œWeb Searchâ€ option  
   - **Deep Web Search**: Toggle â€œDeep Web Searchâ€ if you need to scrape and analyze full page contents  
3. **Enter your query** in the text box.  
4. **Configure additional options (optional)**:
   - **Generate Mind Map**: Visualize concepts related to your query  
   - **Agent Search**: Enable for complex queries; pick a strategy (Direct or Informed Decomposition)  
   - **Number of Results**: Adjust how many results to retrieve  
5. **Submit your query** and view the response.  
6. **Explore source documents or web sources** that informed the answer.

### ğŸŒ Web Search
1. Toggle the â€œWeb Searchâ€ or â€œDeep Web Searchâ€ option on the main interface.  
2. Enter your query.  
3. The system will:
   - Search the web using SearXNG.  
   - Optionally scrape and analyze page content (Deep Web Search).  
   - Use an LLM to interpret and synthesize the findings.  
   - Present a comprehensive answer along with source links.

### ğŸ¤– Agent Search
1. Enable the â€œAgent Searchâ€ checkbox.  
2. Choose a strategy:
   - **Direct Decomposition**: Breaks down your question into sub-queries immediately.  
   - **Informed Decomposition**: Performs a preliminary search, then refines sub-queries based on initial results.  
3. Submit your query to receive a comprehensive answer assembled from multiple targeted searches.

### ğŸ‘¤ Admin Interface
1. **Login** with admin credentials (specified in your `.env` file).  
2. **Create new collections** from the admin dashboard.  
3. **Upload documents** to collections.  
4. Documents are automatically processed and made available for retrieval in user queries.

## ğŸ› ï¸ Technical Implementation

- ğŸŒ **Flask**: Web framework for the application  
- ğŸ—„ï¸ **Qdrant**: Vector database for storing and retrieving document embeddings  
- ğŸ” **SearXNG**: Self-hosted search engine for web search capabilities  
- ğŸ¤– **Agent Framework**: Custom implementation for query decomposition and result synthesis  
- ğŸ§  **Mind Map Generation**: Visualization of query responses and related concepts  
- ğŸ”¤ **Embedding Models**:
  - **SentenceTransformers**: Local embedding models (fallback)  
  - **OpenAI Embeddings**: High-quality embeddings when API key is set  
  - **Ollama Embeddings**: Local embeddings when Ollama is configured  
- ğŸ”Œ **Model Management**: Dynamic provider detection and configuration based on environment variables  
- ğŸ” **Flask-Login**: For admin authentication  
- ğŸ“š **Python Libraries**: For document processing (PyPDF2, BeautifulSoup, etc.)  
- ğŸ“„ **Docling**: Advanced document processing for text extraction in various file formats  

## ğŸ“Š System Architecture

Below are detailed flowcharts of WebRAgent's key workflows and components.

### System Overview

The following diagram shows the high-level architecture of WebRAgent, illustrating how all components interact with each other and external systems:

![WebRAgent System Overview](https://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.githubusercontent.com/dkruyt/WebRAgent/main/docs_flowcharts.puml&start=WebRAgent%20System%20Overview&end=@enduml)

### Document Upload and Processing

This workflow shows how documents are uploaded, processed, chunked, and stored in both MongoDB and the Qdrant vector database:

![Document Upload Workflow](https://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.githubusercontent.com/dkruyt/WebRAgent/main/docs_flowcharts.puml&start=Document%20Upload%20and%20Processing%20Workflow&end=@enduml)

### Text Extraction and Chunking

This diagram illustrates how text is extracted from various document formats and chunked for optimal retrieval:

![Text Extraction Workflow](https://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.githubusercontent.com/dkruyt/WebRAgent/main/docs_flowcharts.puml&start=Text%20Extraction%20and%20Chunking%20Workflow&end=@enduml)

### Vector Embedding and Storage

This shows how document chunks are embedded and stored in the vector database:

![Vector Embedding Workflow](https://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.githubusercontent.com/dkruyt/WebRAgent/main/docs_flowcharts.puml&start=Vector%20Embedding%20and%20Storage%20Workflow&end=@enduml)

### RAG Query Processing

This diagram details how user queries are processed in the standard RAG workflow:

![RAG Query Workflow](https://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.githubusercontent.com/dkruyt/WebRAgent/main/docs_flowcharts.puml&start=RAG%20(Retrieval-Augmented%20Generation)%20Query%20Workflow&end=@enduml)

### Agent Search Workflow

This shows how complex queries are decomposed and processed by the agent search feature:

![Agent Search Workflow](https://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.githubusercontent.com/dkruyt/WebRAgent/main/docs_flowcharts.puml&start=Agent%20Search%20Workflow&end=@enduml)

### Web Search Workflow

This diagram explains how web searches are processed:

![Web Search Workflow](https://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.githubusercontent.com/dkruyt/WebRAgent/main/docs_flowcharts.puml&start=Web%20Search%20Workflow&end=@enduml)

### Chat Workflow

This illustrates how chat sessions are managed and processed:

![Chat Workflow](https://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.githubusercontent.com/dkruyt/WebRAgent/main/docs_flowcharts.puml&start=Chat%20Workflow&end=@enduml)

## ğŸ“‚ Project Structure

```
WebRAgent/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ models/             # Data models
â”‚   â”‚   â”œâ”€â”€ chat.py         # Chat session models
â”‚   â”‚   â”œâ”€â”€ collection.py   # Document collection models
â”‚   â”‚   â”œâ”€â”€ document.py     # Document models and metadata
â”‚   â”‚   â””â”€â”€ user.py         # User authentication models
â”‚   â”œâ”€â”€ routes/             # Route handlers
â”‚   â”‚   â”œâ”€â”€ admin.py        # Admin interface routes
â”‚   â”‚   â”œâ”€â”€ auth.py         # Authentication routes
â”‚   â”‚   â”œâ”€â”€ chat.py         # Chat interface routes
â”‚   â”‚   â””â”€â”€ main.py         # Main application routes
â”‚   â”œâ”€â”€ services/           # Business logic
â”‚   â”‚   â”œâ”€â”€ agent_search_service.py     # Query decomposition and agent search
â”‚   â”‚   â”œâ”€â”€ chat_service.py             # Chat session management
â”‚   â”‚   â”œâ”€â”€ claude_service.py           # Anthropic Claude integration
â”‚   â”‚   â”œâ”€â”€ document_service.py         # Document processing
â”‚   â”‚   â”œâ”€â”€ llm_service.py              # LLM provider abstraction
â”‚   â”‚   â”œâ”€â”€ mindmap_service.py          # Mind map generation
â”‚   â”‚   â”œâ”€â”€ model_service.py            # Dynamic model management
â”‚   â”‚   â”œâ”€â”€ ollama_service.py           # Ollama integration
â”‚   â”‚   â”œâ”€â”€ openai_service.py           # OpenAI integration
â”‚   â”‚   â”œâ”€â”€ qdrant_service.py           # Vector database operations
â”‚   â”‚   â”œâ”€â”€ rag_service.py              # Core RAG functionality
â”‚   â”‚   â”œâ”€â”€ searxng_service.py          # Web search integration
â”‚   â”‚   â””â”€â”€ web_search_agent_service.py # Web search with agent capabilities
â”‚   â”œâ”€â”€ static/             # CSS, JS, and other static files
â”‚   â”œâ”€â”€ templates/          # Jinja2 templates
â”‚   â””â”€â”€ __init__.py         # Flask application factory
â”œâ”€â”€ data/                   # Created at runtime for data storage
â”‚   â”œâ”€â”€ collections/        # Collection metadata storage
â”‚   â”œâ”€â”€ documents/          # Document metadata storage
â”‚   â”œâ”€â”€ models/             # Model configuration storage
â”‚   â”‚   â”œâ”€â”€ config.json     # Dynamic model configuration
â”‚   â”‚   â””â”€â”€ dimensions.json # Embedding model dimensions
â”‚   â””â”€â”€ uploads/            # Uploaded document files
â”œâ”€â”€ searxng/                # SearXNG configuration
â”œâ”€â”€ .dockerignore           # Files to exclude from Docker build
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ .env.example            # Example environment file
â”œâ”€â”€ .gitignore              # Git ignore patterns
â”œâ”€â”€ docker-compose.yml      # Docker Compose config
â”œâ”€â”€ docker-compose.gpu.yml  # Docker Compose config with GPU support
â”œâ”€â”€ Dockerfile              # Docker build instructions
â”œâ”€â”€ requirements.txt        # Project dependencies
â”œâ”€â”€ README.md               # Project documentation
â””â”€â”€ run.py                  # Application entry point
```

## ğŸ”’ Security Notes

- ğŸ›¡ï¸ In a production environment, use a proper database with password hashing  
- ğŸ” Configure HTTPS for secure communication  
- ğŸ”‘ Set a strong, unique `FLASK_SECRET_KEY`  
- ğŸš« Do not expose admin routes to the public internet without proper security measures  

## ğŸ“œ License

MIT

## ğŸ“ Copyright

Â© 2024 Dennis Kruyt. All rights reserved.

## ğŸ™ Acknowledgements

- ğŸ—„ï¸ [Qdrant](https://qdrant.tech/)  
- ğŸ”¤ [SentenceTransformers](https://www.sbert.net/)  
- ğŸŒ [Flask](https://flask.palletsprojects.com/)  
- ğŸ“„ [Docling](https://github.com/doclingjs/docling)  
- ğŸ” [SearXNG](https://docs.searxng.org/)  
- ğŸ¤– [OpenAI](https://openai.com/)  
- ğŸ§  [Anthropic](https://www.anthropic.com/)  
- ğŸ¦™ [Ollama](https://ollama.ai/)  
